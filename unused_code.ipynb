{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first lets create numerical data out of the offer_type, since it is either ```bogo```, ```discount``` or ```informational``` . Lateron we can remove the last column since being dependant of the first two when using the dataframe for training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio = pd.concat([portfolio, pd.get_dummies(portfolio.offer_type)[['bogo','discount','informational']]],axis=1)\n",
    "# portfolio.drop('offer_type',axis=1,inplace=True)\n",
    "# portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets also proceed in the same manner with the ```channels```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find all unique values of chanenls \n",
    "\n",
    "# unique_channels = list(set(portfolio.channels.sum())) #what are possible channels\n",
    "# unique_channels= [str(channel) for channel in unique_channels] #convert to non unicode strings\n",
    "\n",
    "\n",
    "# # create columns for unique values of channels and do one-hot-encoding - later we might want to reduce it by one dependant column\n",
    "\n",
    "# for channel in unique_channels:\n",
    "#     portfolio[channel] = portfolio['channels'].apply(lambda x: 1 if channel in x else 0)\n",
    "# portfolio.drop('channels',axis=1, inplace=True)\n",
    "\n",
    "# portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets proceed with the next dataframe - profile  \n",
    "here we need to make gender as separate columns and clean regarding age and income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets convert the male/female/other entries into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "# #the reward is generally 0 on info offers but should be nan if there was not even a view or a view after the validity \n",
    "# customer_offers.loc[customer_offers['offer_id']==offer_id,'reward'] = 0 * customer_offers['time_completed'] #keeping nan as nan and others to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_trans = transcript[transcript['person']=='0cc6e8553c844c02ab525bc466aa569b']\n",
    "# sample =customer_offers[customer_offers['person']=='0cc6e8553c844c02ab525bc466aa569b']\n",
    "# sub_group_ranges = list(zip(sample['time viewed'], sample['time completed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_min_max = [min(x) for x in sub_group_ranges]+[max(x) for x in sub_group_ranges]\n",
    "# min_ = min(find_min_max)\n",
    "# max_ = max(find_min_max)\n",
    "# temp_ary = np.arange(min_,max_+1)\n",
    "# temp_dic = dict((el,0) for el in temp_ary)\n",
    "# print(min_,max_)\n",
    "\n",
    "# for tup in sub_group_ranges:\n",
    "#     print(tup)\n",
    "    \n",
    "#     if not(np.isnan(np.sum(tup))):\n",
    "#         run_ary = (np.arange(tup[0],tup[1]+1))\n",
    "#         print(run_ary)\n",
    "#         for j in run_ary:\n",
    "#             temp_dic[j]=temp_dic[j]+1\n",
    "            \n",
    "# temp_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for trange in sub_group_ranges:\n",
    "#     print(trange)\n",
    "#     sample_trans[str(trange)] = sample_trans.apply(lambda x: filter_time_range(x,trange),axis=1)\n",
    "# dfg_per_offer=sample_trans.groupby(['person']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people = list(transcript['person'])[:100]\n",
    "# for person in people:\n",
    "#     if (transcript[transcript['person']==person]['amount'].value_counts().max()) > 1:\n",
    "#         print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript[transcript['person']==person]['amount'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum((np.nan, 594.0))\n",
    "# overlap([(60.0, 186.0), (336.0, 342.0), (168.0, np.nan), (np.nan, 594.0), (510.0, 594.0), (576.0, 594.0)])\n",
    "# overlap([(108.0, np.nan), (504.0, 522.0), (174.0, 252.0), (336.0, 342.0), (594.0, 630.0), (np.nan, np.nan)])\n",
    "# p = list(transcript.groupby('person').count().sort_values('event', ascending=False).index)\n",
    "# p.index('0cc6e8553c844c02ab525bc466aa569b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

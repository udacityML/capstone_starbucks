{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining which columns are to be kept from the complete feature data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['person','time','amount', 'offer_id', 'time_received', 'time_viewed', 'mobile', 'email', 'social', 'web','converted','delta_time_reception_viewed','prev_person',\n",
    "       'delta_time_viewed_completion','gender','O','time_completed', 'reward', 'potential_reward', 'duration','offer_type', 'difficulty','is_transaction', ]\n",
    "kept_features = [ 'person',\n",
    "       'age', 'income', 'F', 'M', 'member_since_month','viewed',  'is_completed',\n",
    "       'count_offers_completed', 'count_offers_viewed', 'count_transactions','avg_spending', 'avg_reward',  'delta_time_reception_viewed_avg',\n",
    "       'delta_time_viewed_completion_avg', 'bogo','discount', 'informational']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in features after feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``features`` contains the data which has been created in the preprocessing and feature engineering part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(data_dir, 'features.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the first test we will only look at bogo data to check some model performance.  \n",
    "if we only want to run the demographic data we can switch it for the processing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_demographic_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features[features.bogo.isnull()==False].copy()\n",
    "df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "df = df[kept_features]\n",
    "\n",
    "# remove columns not wanted because they represent the target. person as id is not needed\n",
    "df = df.drop(['person','discount','informational','is_completed'],axis=1)\n",
    "if run_demographic_only:\n",
    "    demographic = ['age','income','F','M','member_since_month','bogo']\n",
    "    df = df[demographic].copy()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'income', u'F', u'M', u'member_since_month', u'bogo'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an overview of which models might deliver good results lets look at basic models without any optimization. For this i chose sklearn to create confusion matrices and classification reports to get an idea on which model performs how. the metrics are run on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sacling the data by ```MinMaxScaler``` to avoid large numbers to be put into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = pd.DataFrame(scaler.fit_transform(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting into train and test set. training set will be split further into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df_y: 19763, \n",
      "length of df_X: 19763\n",
      "train: 9683,\n",
      "valid: 4151,\n",
      "test: 5929\n"
     ]
    }
   ],
   "source": [
    "df_y = scaled.iloc[:,-1:]\n",
    "df_X = scaled.iloc[:,:-1]\n",
    "print('length of df_y: {}, \\nlength of df_X: {}'.format(len(df_y),len(df_X)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "print('train: {},\\nvalid: {},\\ntest: {}'.format(len(y_train),len(y_valid),len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking ```LogisticRegression```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1597 1120]\n",
      " [ 945 2267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.59      0.61      2717\n",
      "         1.0       0.67      0.71      0.69      3212\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      5929\n",
      "   macro avg       0.65      0.65      0.65      5929\n",
      "weighted avg       0.65      0.65      0.65      5929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LogisticRegression()\n",
    "lm.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = lm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking different parameters for ``support vector classifiers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "[[1176  863]\n",
      " [ 533 2444]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.58      0.63      2039\n",
      "         1.0       0.74      0.82      0.78      2977\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      5016\n",
      "   macro avg       0.71      0.70      0.70      5016\n",
      "weighted avg       0.72      0.72      0.72      5016\n",
      "\n",
      "rbf\n",
      "[[1236  803]\n",
      " [ 560 2417]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.61      0.64      2039\n",
      "         1.0       0.75      0.81      0.78      2977\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5016\n",
      "   macro avg       0.72      0.71      0.71      5016\n",
      "weighted avg       0.73      0.73      0.72      5016\n",
      "\n",
      "poly\n",
      "[[1167  872]\n",
      " [ 472 2505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.57      0.63      2039\n",
      "         1.0       0.74      0.84      0.79      2977\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5016\n",
      "   macro avg       0.73      0.71      0.71      5016\n",
      "weighted avg       0.73      0.73      0.73      5016\n",
      "\n",
      "poly\n",
      "[[1291  748]\n",
      " [ 493 2484]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.63      0.68      2039\n",
      "         1.0       0.77      0.83      0.80      2977\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5016\n",
      "   macro avg       0.75      0.73      0.74      5016\n",
      "weighted avg       0.75      0.75      0.75      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['rbf', 'poly']:\n",
    "    for gamma in [1, 5]:\n",
    "        print(kernel)\n",
    "        svm = SVC(kernel=kernel, gamma=gamma)\n",
    "        svm.fit(X_train.values,y_train.values.squeeze())\n",
    "        y_pred = svm.predict(X_test)\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing for ``stochastic gradient decent classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1291  748]\n",
      " [ 493 2484]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.63      0.68      2039\n",
      "         1.0       0.77      0.83      0.80      2977\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5016\n",
      "   macro avg       0.75      0.73      0.74      5016\n",
      "weighted avg       0.75      0.75      0.75      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgdc = SGDClassifier()\n",
    "sgdc.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ``random forest classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1350  689]\n",
      " [ 556 2421]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.66      0.68      2039\n",
      "         1.0       0.78      0.81      0.80      2977\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5016\n",
      "   macro avg       0.74      0.74      0.74      5016\n",
      "weighted avg       0.75      0.75      0.75      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=19)\n",
    "forest.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = forest.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ``xgboost``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost does not seem to work with pip install in the aws environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#xgb = XGBClassifier(gamma=6)\n",
    "#xgb.fit(X_train.values,y_train.values.squeeze())\n",
    "#y_pred = xgb.predict(X_test.values)\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transferal to Sagemaker and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without any further configuration, the models perform quite similarly. xgboost model had the highest rates regarding precision and recall. lets quickly recap what precision and recall are:  \n",
    "recall = TP /(TP + FN)  \n",
    "precision = TP / (TP + FP)  \n",
    "  \n",
    "now lets prepare Amazon Sagemaker for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uploading the data to an S3 bucket to be able to work with the data in sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we repeat the steps mentioned above to create the data which can be fed to the model. we will create one training for each offer_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offer type: bogo \n",
      "length of df_y: 19763, \n",
      "length of df_X: 19763\n",
      "train: 9683,\n",
      "valid: 4151,\n",
      "test: 5929\n",
      "offer type: discount \n",
      "length of df_y: 16585, \n",
      "length of df_X: 16585\n",
      "train: 8126,\n",
      "valid: 3483,\n",
      "test: 4976\n",
      "offer type: informational \n",
      "length of df_y: 9360, \n",
      "length of df_X: 9360\n",
      "train: 4586,\n",
      "valid: 1966,\n",
      "test: 2808\n"
     ]
    }
   ],
   "source": [
    "offer_types = ['bogo','discount','informational']\n",
    "for offer_type in offer_types:\n",
    "    df = features[features[offer_type].isnull()==False].copy()\n",
    "    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    df = df[kept_features]\n",
    "\n",
    "    # we have to ensure that the colum 'bogo' has to be removed when processing the bogo offer trype. same procedure\n",
    "    # when processing the other offer types\n",
    "    remaining_offers = list(offer_types)\n",
    "    remaining_offers.remove(offer_type)\n",
    "    df = df.drop(['person','is_completed']+remaining_offers,axis=1)\n",
    "    \n",
    "    if run_demographic_only:\n",
    "        demographic = ['age','income','F','M','member_since_month',offer_type]\n",
    "        df = df[demographic].copy()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # scale the data to avoid large numbers to be fed into the  model\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "    \n",
    "    # separate y and X from whole data frame and create sets after train-test-split\n",
    "    df_y = scaled.iloc[:,-1:]\n",
    "    df_X = scaled.iloc[:,:-1]\n",
    "    print('offer type: {} \\nlength of df_y: {}, \\nlength of df_X: {}'.format(offer_type, len(df_y),len(df_X)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "    print('train: {},\\nvalid: {},\\ntest: {}'.format(len(y_train),len(y_val),len(y_test)))\n",
    "    \n",
    "    # lets write the data to data directory\n",
    "    X_test.to_csv(os.path.join(data_dir, '{}_test.csv'.format(offer_type)), header=False, index=False)\n",
    "    y_test.to_csv(os.path.join(data_dir, '{}_y_test.csv'.format(offer_type)), header=False, index=False)\n",
    "    pd.concat([y_val, X_val], axis=1).to_csv(os.path.join(data_dir, '{}_validation.csv'.format(offer_type)), header=False, index=False)\n",
    "    pd.concat([y_train, X_train], axis=1).to_csv(os.path.join(data_dir, '{}_train.csv'.format(offer_type)), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets upload the created data to S3 and write the S3 locations into a dictionary of the form {offer:{test:...,train...,validation}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_validation.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_validation.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_validation.csv\n"
     ]
    }
   ],
   "source": [
    "prefix = 'capstone_starbucks_20201110'\n",
    "locations = {}\n",
    "for offer_type in offer_types:\n",
    "    usage_dict = {}\n",
    "    for usage in ['train','test','validation']:\n",
    "        location = session.upload_data(os.path.join(data_dir, '{}_{}.csv'.format(offer_type,usage)), key_prefix=prefix)\n",
    "        usage_dict[usage] = location\n",
    "        print(location)\n",
    "    locations[offer_type] = usage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bogo': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/bogo_validation.csv'},\n",
       " 'discount': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/discount_validation.csv'},\n",
       " 'informational': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201110/informational_validation.csv'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train a single xgboost model by getting a container that holds the model algorithm to create the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_test(offer_type,usage):\n",
    "    '''\n",
    "    get the data of a specific offer type and depending on useage (training,validation,test) \n",
    "    '''\n",
    "    return pd.read_csv(os.path.join(data_dir,'{}_y_{}.csv'.format(offer_type,usage)),header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_image_uri only available in python 2 / Sagemaker < 2\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, # The name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge', # The type of instance ot use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                                                        # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a set of hyper parameters is set\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect the locations\n",
    "offer_type = 'bogo'\n",
    "train_location = locations[offer_type]['train']\n",
    "val_location = locations[offer_type]['validation']\n",
    "test_location = locations[offer_type]['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just train one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-06 14:02:33 Starting - Starting the training job...\n",
      "2020-11-06 14:02:36 Starting - Launching requested ML instances......\n",
      "2020-11-06 14:03:40 Starting - Preparing the instances for training...\n",
      "2020-11-06 14:04:30 Downloading - Downloading input data...\n",
      "2020-11-06 14:04:46 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8469.97mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:08] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:08] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.467407#011validation-rmse:0.469731\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.445431#011validation-rmse:0.450377\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.430298#011validation-rmse:0.437217\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.419934#011validation-rmse:0.428734\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.412625#011validation-rmse:0.422641\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.407422#011validation-rmse:0.418249\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.403053#011validation-rmse:0.415496\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.400301#011validation-rmse:0.413159\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.398216#011validation-rmse:0.411852\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.396678#011validation-rmse:0.410958\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.39516#011validation-rmse:0.410636\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.394337#011validation-rmse:0.410398\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.393322#011validation-rmse:0.410127\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.392339#011validation-rmse:0.409808\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.391885#011validation-rmse:0.409834\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.39105#011validation-rmse:0.40968\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.390621#011validation-rmse:0.409684\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.389694#011validation-rmse:0.409607\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.389492#011validation-rmse:0.40972\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.388482#011validation-rmse:0.409889\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.388354#011validation-rmse:0.409819\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.387613#011validation-rmse:0.410005\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.387175#011validation-rmse:0.409996\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.386842#011validation-rmse:0.409922\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.386368#011validation-rmse:0.410266\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.386225#011validation-rmse:0.41032\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.385885#011validation-rmse:0.410388\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.385452#011validation-rmse:0.410511\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.389694#011validation-rmse:0.409607\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-06 14:05:20 Uploading - Uploading generated training model\n",
      "2020-11-06 14:05:20 Completed - Training job completed\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    }
   ],
   "source": [
    "# here only a single training is done\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the model\n",
    "forward prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[32m2020-11-06T14:10:29.446:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy data from S3 to local data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-06-14-05-45-916/bogo_test.csv.out to data/bogo_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare the predictions with the test targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(os.path.join(data_dir, 'bogo_test.csv.out'), header=None)\n",
    "y_test = get_y_test('bogo','test')\n",
    "print(confusion_matrix(y_test,y_pred.round()))\n",
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train models with one model per offer type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that we have trained one model with one offer_type we can try to train different models for different offer types as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-10 22:55:41 Starting - Starting the training job...\n",
      "2020-11-10 22:55:44 Starting - Launching requested ML instances......\n",
      "2020-11-10 22:56:51 Starting - Preparing the instances for training......\n",
      "2020-11-10 22:58:03 Downloading - Downloading input data\n",
      "2020-11-10 22:58:03 Training - Downloading the training image...\n",
      "2020-11-10 22:58:36 Uploading - Uploading generated training model\n",
      "2020-11-10 22:58:36 Completed - Training job completed\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-10:22:58:24:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-10:22:58:24:INFO] File size need to be processed in the node: 0.84mb. Available memory size in the node: 8481.01mb\u001b[0m\n",
      "\u001b[34m[2020-11-10:22:58:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:58:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[22:58:24] 9683x5 matrix with 48415 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-10:22:58:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[22:58:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[22:58:24] 4151x5 matrix with 20755 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.479687#011validation-rmse:0.480641\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.466296#011validation-rmse:0.467792\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 48 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.45799#011validation-rmse:0.460133\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 46 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.452207#011validation-rmse:0.455473\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 46 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.448177#011validation-rmse:0.452198\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.445864#011validation-rmse:0.449906\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.44408#011validation-rmse:0.448132\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 56 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.442894#011validation-rmse:0.447125\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.44189#011validation-rmse:0.44617\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.441288#011validation-rmse:0.445639\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.440991#011validation-rmse:0.445361\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.440748#011validation-rmse:0.44511\u001b[0m\n",
      "\u001b[34m[22:58:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.440536#011validation-rmse:0.444988\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.440533#011validation-rmse:0.444982\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.440533#011validation-rmse:0.444981\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.440533#011validation-rmse:0.444982\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.440367#011validation-rmse:0.444896\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.440367#011validation-rmse:0.444895\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.440366#011validation-rmse:0.444894\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.440367#011validation-rmse:0.444893\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.440368#011validation-rmse:0.444891\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.440367#011validation-rmse:0.444891\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.440368#011validation-rmse:0.44489\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.440367#011validation-rmse:0.444891\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.440367#011validation-rmse:0.444893\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.440367#011validation-rmse:0.444894\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.440367#011validation-rmse:0.444893\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.440367#011validation-rmse:0.444891\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.440368#011validation-rmse:0.44489\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.440369#011validation-rmse:0.44489\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.440367#011validation-rmse:0.444891\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.440368#011validation-rmse:0.44489\u001b[0m\n",
      "\u001b[34m[22:58:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.44037#011validation-rmse:0.44489\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.440368#011validation-rmse:0.44489\n",
      "\u001b[0m\n",
      "Training seconds: 54\n",
      "Billable seconds: 54\n",
      "................................................\n",
      "\u001b[32m2020-11-10T23:06:42.011:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:41 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:41 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:41 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:41 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:41 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:41:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:41:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:42 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:42:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:06:42 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:42:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:42:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:06:42:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:41 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:41 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:41 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:41 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:41 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:41:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:41:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:42 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:42:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:06:42 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:42:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:42:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:06:42:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-10-22-58-53-373/bogo_test.csv.out to data/bogo_test.csv.out\n",
      "2020-11-10 23:07:09 Starting - Starting the training job...\n",
      "2020-11-10 23:07:11 Starting - Launching requested ML instances......\n",
      "2020-11-10 23:08:16 Starting - Preparing the instances for training...\n",
      "2020-11-10 23:09:05 Downloading - Downloading input data......\n",
      "2020-11-10 23:10:06 Training - Training image download completed. Training in progress.\n",
      "2020-11-10 23:10:06 Uploading - Uploading generated training model.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:10:01:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:10:01:INFO] File size need to be processed in the node: 0.71mb. Available memory size in the node: 8483.79mb\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:10:01:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:10:01] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:10:01] 8126x5 matrix with 40630 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:10:01:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:10:01] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:10:01] 3483x5 matrix with 17415 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 44 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.467973#011validation-rmse:0.468967\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 56 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.446678#011validation-rmse:0.448378\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.432698#011validation-rmse:0.435166\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 56 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.423458#011validation-rmse:0.426256\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.417153#011validation-rmse:0.420482\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 56 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.413249#011validation-rmse:0.41672\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.410643#011validation-rmse:0.414129\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 60 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.409035#011validation-rmse:0.412654\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.407621#011validation-rmse:0.411515\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.406918#011validation-rmse:0.410882\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.406432#011validation-rmse:0.410453\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 54 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.406068#011validation-rmse:0.410193\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.405982#011validation-rmse:0.410119\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.40593#011validation-rmse:0.410076\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.405903#011validation-rmse:0.410054\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.40587#011validation-rmse:0.410029\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.405855#011validation-rmse:0.410019\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.405851#011validation-rmse:0.410017\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.40563#011validation-rmse:0.409922\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.405622#011validation-rmse:0.409918\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.405622#011validation-rmse:0.409917\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.405614#011validation-rmse:0.409914\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.405609#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.405609#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.405609#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.405608#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.40561#011validation-rmse:0.409912\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.405609#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.405608#011validation-rmse:0.409915\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.405607#011validation-rmse:0.409915\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.405608#011validation-rmse:0.409916\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.405608#011validation-rmse:0.409918\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.405608#011validation-rmse:0.409917\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.405607#011validation-rmse:0.409915\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.405608#011validation-rmse:0.409915\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.405608#011validation-rmse:0.409914\u001b[0m\n",
      "\u001b[34m[23:10:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.405609#011validation-rmse:0.409913\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.40561#011validation-rmse:0.409912\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-10 23:10:13 Completed - Training job completed\n",
      "Training seconds: 68\n",
      "Billable seconds: 68\n",
      ".............................\u001b[32m2020-11-10T23:15:30.075:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:30 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:30 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:15:30 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:30 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:30 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:15:30 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:15:30:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-10-23-10-51-268/discount_test.csv.out to data/discount_test.csv.out\n",
      "2020-11-10 23:16:05 Starting - Starting the training job...\n",
      "2020-11-10 23:16:07 Starting - Launching requested ML instances......\n",
      "2020-11-10 23:17:32 Starting - Preparing the instances for training.........\n",
      "2020-11-10 23:18:52 Downloading - Downloading input data\n",
      "2020-11-10 23:18:52 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:19:12:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:19:12:INFO] File size need to be processed in the node: 0.4mb. Available memory size in the node: 8461.81mb\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:19:12:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:19:12] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:19:12] 4586x5 matrix with 22930 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:19:12:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[23:19:12] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[23:19:12] 1966x5 matrix with 9830 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.489584#011validation-rmse:0.489297\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 50 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.481537#011validation-rmse:0.482455\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.476806#011validation-rmse:0.477828\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.473362#011validation-rmse:0.474679\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.471266#011validation-rmse:0.472492\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.469764#011validation-rmse:0.471431\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.469072#011validation-rmse:0.470766\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.468461#011validation-rmse:0.470005\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.468319#011validation-rmse:0.469683\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 44 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.467878#011validation-rmse:0.469336\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.467834#011validation-rmse:0.469197\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.467803#011validation-rmse:0.469077\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.467794#011validation-rmse:0.46904\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.467793#011validation-rmse:0.469036\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.467777#011validation-rmse:0.468954\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.46777#011validation-rmse:0.468906\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.467769#011validation-rmse:0.468901\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.467409#011validation-rmse:0.468936\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.467411#011validation-rmse:0.468947\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.467407#011validation-rmse:0.46892\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.467402#011validation-rmse:0.468874\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.4674#011validation-rmse:0.468853\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.467401#011validation-rmse:0.468862\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.467399#011validation-rmse:0.468838\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.467401#011validation-rmse:0.468859\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.467405#011validation-rmse:0.468902\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.467403#011validation-rmse:0.468881\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.467402#011validation-rmse:0.468873\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.467399#011validation-rmse:0.468841\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.4674#011validation-rmse:0.468844\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.467403#011validation-rmse:0.46888\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.467405#011validation-rmse:0.468901\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.467404#011validation-rmse:0.46889\u001b[0m\n",
      "\u001b[34m[23:19:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.4674#011validation-rmse:0.468845\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.467399#011validation-rmse:0.468838\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-10 23:19:24 Uploading - Uploading generated training model\n",
      "2020-11-10 23:19:24 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n",
      "..............................\n",
      "\u001b[32m2020-11-10T23:24:37.526:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-10 23:24:37 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-10 23:24:37 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-10:23:24:37:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-10-23-19-48-126/informational_test.csv.out to data/informational_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "for offer_type in offer_types:\n",
    "    train_location = locations[offer_type]['train']\n",
    "    val_location = locations[offer_type]['validation']\n",
    "    test_location = locations[offer_type]['test']\n",
    "    \n",
    "    s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "    s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "    xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "    xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "    trained_models[offer_type] = xgb_transformer.model_name\n",
    "    xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "    xgb_transformer.wait()\n",
    "    !aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bogo': 'xgboost-2020-11-10-22-55-41-410',\n",
       " 'discount': 'xgboost-2020-11-10-23-07-09-021',\n",
       " 'informational': 'xgboost-2020-11-10-23-16-05-671'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the metrics regarding the freshly trained models look as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bogo\n",
      "[[1964  753]\n",
      " [ 982 2230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.72      0.69      2717\n",
      "         1.0       0.75      0.69      0.72      3212\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5929\n",
      "   macro avg       0.71      0.71      0.71      5929\n",
      "weighted avg       0.71      0.71      0.71      5929\n",
      "\n",
      "discount\n",
      "[[ 488  994]\n",
      " [ 362 3132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.33      0.42      1482\n",
      "         1.0       0.76      0.90      0.82      3494\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      4976\n",
      "   macro avg       0.67      0.61      0.62      4976\n",
      "weighted avg       0.70      0.73      0.70      4976\n",
      "\n",
      "informational\n",
      "[[1455  292]\n",
      " [ 666  395]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.83      0.75      1747\n",
      "         1.0       0.57      0.37      0.45      1061\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2808\n",
      "   macro avg       0.63      0.60      0.60      2808\n",
      "weighted avg       0.64      0.66      0.64      2808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for offer_type in offer_types:\n",
    "    print(offer_type)\n",
    "    y_pred = pd.read_csv(os.path.join(data_dir, '{}_test.csv.out'.format(offer_type)), header=None)\n",
    "    y_test = get_y_test(offer_type,'test')\n",
    "    print(confusion_matrix(y_test,y_pred.round()))\n",
    "    print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the trainings reveal a recall that is often not very satisfying we can try some hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'xgboost-201109-1639-014-0de2f067'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u'xgboost-201106-1413-015-b8fd35ee' performs best for all features  \n",
    "u'xgboost-201108-2134-007-1b3a52d4' performs best for only demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'xgboost-201106-1413-015-b8fd35ee'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_attached.base_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-09 16:55:36 Starting - Preparing the instances for training\n",
      "2020-11-09 16:55:36 Downloading - Downloading input data\n",
      "2020-11-09 16:55:36 Training - Training image download completed. Training in progress.\n",
      "2020-11-09 16:55:36 Uploading - Uploading generated training model\n",
      "2020-11-09 16:55:36 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8475.41mb\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:55:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:55:24] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:55:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:55:24] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.491111#011validation-rmse:0.491897\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.48313#011validation-rmse:0.484654\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.475927#011validation-rmse:0.477946\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.469099#011validation-rmse:0.471638\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.462862#011validation-rmse:0.466145\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.457035#011validation-rmse:0.460836\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.451464#011validation-rmse:0.456013\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.446687#011validation-rmse:0.451799\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.442171#011validation-rmse:0.447753\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.438169#011validation-rmse:0.444383\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.43437#011validation-rmse:0.441054\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.43076#011validation-rmse:0.437764\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.42757#011validation-rmse:0.435251\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.424575#011validation-rmse:0.432605\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.421907#011validation-rmse:0.430331\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.419547#011validation-rmse:0.42842\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.417104#011validation-rmse:0.426549\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.415103#011validation-rmse:0.425197\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.413163#011validation-rmse:0.423589\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.411328#011validation-rmse:0.422163\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.409645#011validation-rmse:0.420871\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.408138#011validation-rmse:0.419843\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.406675#011validation-rmse:0.418842\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.405364#011validation-rmse:0.417886\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.403998#011validation-rmse:0.416829\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.402876#011validation-rmse:0.416025\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.401834#011validation-rmse:0.415199\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.400852#011validation-rmse:0.414585\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.399813#011validation-rmse:0.413866\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.399031#011validation-rmse:0.413356\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.398167#011validation-rmse:0.412814\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.397342#011validation-rmse:0.412575\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.396666#011validation-rmse:0.412193\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.396013#011validation-rmse:0.411829\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.395442#011validation-rmse:0.41169\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.394978#011validation-rmse:0.411412\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.394401#011validation-rmse:0.411085\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.393776#011validation-rmse:0.410758\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.393206#011validation-rmse:0.410633\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.392681#011validation-rmse:0.410537\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.392213#011validation-rmse:0.410294\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.391842#011validation-rmse:0.410112\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.391532#011validation-rmse:0.409944\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.391188#011validation-rmse:0.4098\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.390816#011validation-rmse:0.409625\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.390504#011validation-rmse:0.409511\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.390141#011validation-rmse:0.409482\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.389847#011validation-rmse:0.409434\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.389384#011validation-rmse:0.409284\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.389171#011validation-rmse:0.409234\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.388883#011validation-rmse:0.409252\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.388571#011validation-rmse:0.40927\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.388173#011validation-rmse:0.409114\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.387896#011validation-rmse:0.409114\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.387561#011validation-rmse:0.409131\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.387292#011validation-rmse:0.409063\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.387079#011validation-rmse:0.409087\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.386746#011validation-rmse:0.408963\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.386486#011validation-rmse:0.408965\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.386171#011validation-rmse:0.409002\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.385887#011validation-rmse:0.408857\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.385658#011validation-rmse:0.408895\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.385439#011validation-rmse:0.408859\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.385298#011validation-rmse:0.408879\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.385042#011validation-rmse:0.40885\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.384821#011validation-rmse:0.408724\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.384577#011validation-rmse:0.408752\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.38436#011validation-rmse:0.408819\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.384242#011validation-rmse:0.408789\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.38402#011validation-rmse:0.4088\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.383786#011validation-rmse:0.4089\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.383585#011validation-rmse:0.408945\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.383438#011validation-rmse:0.40887\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.383157#011validation-rmse:0.408805\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.382937#011validation-rmse:0.408822\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.382763#011validation-rmse:0.408803\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.384821#011validation-rmse:0.408724\n",
      "\u001b[0m\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the best model from hyperparameter tuning for all three offer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-09 16:55:36 Starting - Preparing the instances for training\n",
      "2020-11-09 16:55:36 Downloading - Downloading input data\n",
      "2020-11-09 16:55:36 Training - Training image download completed. Training in progress.\n",
      "2020-11-09 16:55:36 Uploading - Uploading generated training model\n",
      "2020-11-09 16:55:36 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8475.41mb\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:55:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:55:24] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-09:16:55:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[16:55:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[16:55:24] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 62 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.491111#011validation-rmse:0.491897\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.48313#011validation-rmse:0.484654\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.475927#011validation-rmse:0.477946\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.469099#011validation-rmse:0.471638\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.462862#011validation-rmse:0.466145\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.457035#011validation-rmse:0.460836\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.451464#011validation-rmse:0.456013\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.446687#011validation-rmse:0.451799\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.442171#011validation-rmse:0.447753\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.438169#011validation-rmse:0.444383\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.43437#011validation-rmse:0.441054\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.43076#011validation-rmse:0.437764\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.42757#011validation-rmse:0.435251\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.424575#011validation-rmse:0.432605\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.421907#011validation-rmse:0.430331\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.419547#011validation-rmse:0.42842\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.417104#011validation-rmse:0.426549\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.415103#011validation-rmse:0.425197\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.413163#011validation-rmse:0.423589\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.411328#011validation-rmse:0.422163\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.409645#011validation-rmse:0.420871\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.408138#011validation-rmse:0.419843\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.406675#011validation-rmse:0.418842\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.405364#011validation-rmse:0.417886\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.403998#011validation-rmse:0.416829\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.402876#011validation-rmse:0.416025\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.401834#011validation-rmse:0.415199\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.400852#011validation-rmse:0.414585\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.399813#011validation-rmse:0.413866\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.399031#011validation-rmse:0.413356\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.398167#011validation-rmse:0.412814\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.397342#011validation-rmse:0.412575\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.396666#011validation-rmse:0.412193\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.396013#011validation-rmse:0.411829\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.395442#011validation-rmse:0.41169\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.394978#011validation-rmse:0.411412\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.394401#011validation-rmse:0.411085\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.393776#011validation-rmse:0.410758\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.393206#011validation-rmse:0.410633\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.392681#011validation-rmse:0.410537\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.392213#011validation-rmse:0.410294\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.391842#011validation-rmse:0.410112\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.391532#011validation-rmse:0.409944\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.391188#011validation-rmse:0.4098\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.390816#011validation-rmse:0.409625\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.390504#011validation-rmse:0.409511\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.390141#011validation-rmse:0.409482\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.389847#011validation-rmse:0.409434\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.389384#011validation-rmse:0.409284\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.389171#011validation-rmse:0.409234\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.388883#011validation-rmse:0.409252\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.388571#011validation-rmse:0.40927\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.388173#011validation-rmse:0.409114\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:0.387896#011validation-rmse:0.409114\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.387561#011validation-rmse:0.409131\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.387292#011validation-rmse:0.409063\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.387079#011validation-rmse:0.409087\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.386746#011validation-rmse:0.408963\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.386486#011validation-rmse:0.408965\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.386171#011validation-rmse:0.409002\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.385887#011validation-rmse:0.408857\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.385658#011validation-rmse:0.408895\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.385439#011validation-rmse:0.408859\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.385298#011validation-rmse:0.408879\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.385042#011validation-rmse:0.40885\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.384821#011validation-rmse:0.408724\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.384577#011validation-rmse:0.408752\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.38436#011validation-rmse:0.408819\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.384242#011validation-rmse:0.408789\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.38402#011validation-rmse:0.4088\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.383786#011validation-rmse:0.4089\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.383585#011validation-rmse:0.408945\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.383438#011validation-rmse:0.40887\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.383157#011validation-rmse:0.408805\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.382937#011validation-rmse:0.408822\u001b[0m\n",
      "\u001b[34m[16:55:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.382763#011validation-rmse:0.408803\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.384821#011validation-rmse:0.408724\n",
      "\u001b[0m\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n",
      "xgboost-201109-1639-014-0de2f067\n",
      "........................................\u001b[32m2020-11-09T17:12:20.226:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:12:20 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:12:20 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:12:20:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-201109-1639-014-0de2f067-2020-11-09-17-05-50-205/bogo_test.csv.out to data/bogo_test.csv.out\n",
      "xgboost-201109-1639-014-0de2f067\n",
      ".................................\n",
      ".\u001b[32m2020-11-09T17:18:33.457:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:18:33 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:18:33 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:18:33:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-201109-1639-014-0de2f067-2020-11-09-17-13-07-697/discount_test.csv.out to data/discount_test.csv.out\n",
      "xgboost-201109-1639-014-0de2f067\n",
      ".............................\u001b[32m2020-11-09T17:23:30.268:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-09 17:23:30 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-09 17:23:30 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-09:17:23:30:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-201109-1639-014-0de2f067-2020-11-09-17-18-52-501/informational_test.csv.out to data/informational_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())\n",
    "for offer_type in offer_types:\n",
    "    train_location = locations[offer_type]['train']\n",
    "    val_location = locations[offer_type]['validation']\n",
    "    test_location = locations[offer_type]['test']\n",
    "\n",
    "    xgb_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "    xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "    print(xgb_transformer.model_name)\n",
    "    xgb_transformer.wait()\n",
    "    !aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "\u001b[32m2020-11-06T14:50:55.380:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 40\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())\n",
    "xgb_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-201106-1413-015-b8fd35ee-2020-11-06-14-46-30-851/bogo_test.csv.out to data/bogo_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1352  687]\n",
      " [ 494 2483]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.66      0.70      2039\n",
      "         1.0       0.78      0.83      0.81      2977\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5016\n",
      "   macro avg       0.76      0.75      0.75      5016\n",
      "weighted avg       0.76      0.76      0.76      5016\n",
      "\n",
      "[[ 687  382]\n",
      " [ 824 2334]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.64      0.53      1069\n",
      "         1.0       0.86      0.74      0.79      3158\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      4227\n",
      "   macro avg       0.66      0.69      0.66      4227\n",
      "weighted avg       0.76      0.71      0.73      4227\n",
      "\n",
      "[[503 993]\n",
      " [252 676]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.34      0.45      1496\n",
      "         1.0       0.41      0.73      0.52       928\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      2424\n",
      "   macro avg       0.54      0.53      0.48      2424\n",
      "weighted avg       0.57      0.49      0.48      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for offer_type in offer_types:\n",
    "    y_pred = pd.read_csv(os.path.join(data_dir, '{}_test.csv.out'.format(offer_type)), header=None)\n",
    "    y_test = get_y_test(offer_type,'test')\n",
    "    print(confusion_matrix(y_test,y_pred.round()))\n",
    "    print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining which columns are to be kept from the complete feature data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['person','time','amount', 'offer_id', 'time_received', 'time_viewed', 'mobile', 'email', 'social', 'web','converted','delta_time_reception_viewed','prev_person',\n",
    "       'delta_time_viewed_completion','gender','O','time_completed', 'reward', 'potential_reward', 'duration','offer_type', 'difficulty','is_transaction', ]\n",
    "kept_features = [ 'person',\n",
    "       'age', 'income', 'F', 'M', 'member_since_month','viewed',  'is_completed',\n",
    "       'count_offers_completed', 'count_offers_viewed', 'count_transactions','avg_spending', 'avg_reward',  'delta_time_reception_viewed_avg',\n",
    "       'delta_time_viewed_completion_avg', 'bogo','discount', 'informational']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in features after feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(os.path.join(data_dir, 'features.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the first test we will only look at bogo data to check some model performance. if we only want to run the demographic data we can switch it for the processing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_demographic_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features[features.bogo.isnull()==False].copy()\n",
    "df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "df = df[kept_features]\n",
    "\n",
    "# remove columns not wanted\n",
    "df = df.drop(['person','discount','informational','is_completed'],axis=1)\n",
    "if run_demographic_only:\n",
    "    demographic = ['age','income','F','M','member_since_month','bogo']\n",
    "    df = df[demographic].copy()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'income', u'F', u'M', u'member_since_month', u'viewed',\n",
       "       u'count_offers_completed', u'count_offers_viewed',\n",
       "       u'count_transactions', u'avg_spending', u'avg_reward',\n",
       "       u'delta_time_reception_viewed_avg', u'delta_time_viewed_completion_avg',\n",
       "       u'bogo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get an overview of which models might deliver good results lets look at basic models without any optimization. For this i chose sklearn to create confusion matrices and classification reports to get an idea on which model performs how. the metrics are run on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sacling the data by ```MinMaxScaler```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p27/lib/python2.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype bool, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = pd.DataFrame(scaler.fit_transform(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting into train and test set. training set will be split further into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of df_y: 16717, \n",
      "length of df_X: 16717\n",
      "train: 8190,\n",
      "valid: 3511,\n",
      "test: 5016\n"
     ]
    }
   ],
   "source": [
    "df_y = scaled.iloc[:,-1:]\n",
    "df_X = scaled.iloc[:,:-1]\n",
    "print('length of df_y: {}, \\nlength of df_X: {}'.format(len(df_y),len(df_X)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "print('train: {},\\nvalid: {},\\ntest: {}'.format(len(y_train),len(y_valid),len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking ```LogisticRegression```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1135  904]\n",
      " [ 606 2371]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.56      0.60      2039\n",
      "         1.0       0.72      0.80      0.76      2977\n",
      "\n",
      "    accuracy                           0.70      5016\n",
      "   macro avg       0.69      0.68      0.68      5016\n",
      "weighted avg       0.69      0.70      0.69      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LogisticRegression()\n",
    "lm.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = lm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking different parameters for ``support vector classifiers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in ['rbf', 'poly']:\n",
    "    for gamma in [1, 5]:\n",
    "        print(kernel)\n",
    "        svm = SVC(kernel=kernel, gamma=gamma)\n",
    "        svm.fit(X_train.values,y_train.values.squeeze())\n",
    "        y_pred = svm.predict(X_test)\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing for ``stochastic gradient decent classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc = SGDClassifier()\n",
    "sgdc.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ``random forest classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=19)\n",
    "forest.fit(X_train.values,y_train.values.squeeze())\n",
    "y_pred = forest.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing ``xgboost``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost does not seem to install in the aws environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#xgb = XGBClassifier(gamma=6)\n",
    "#xgb.fit(X_train.values,y_train.values.squeeze())\n",
    "#y_pred = xgb.predict(X_test.values)\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model transferal to Sagemaker and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without any further configuration, the models perform quite similarly. xgboost model had the highest rates regarding precision and recall. lets quickly recap what precision and recall are:  \n",
    "recall = TP /(TP + FN)  \n",
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uploading the data to an S3 bucket to be able to work with the data in sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we repeat the steps mentioned above to create the data which can be fed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offer type: bogo \n",
      "length of df_y: 16717, \n",
      "length of df_X: 16717\n",
      "train: 8190,\n",
      "valid: 3511,\n",
      "test: 5016\n",
      "offer type: discount \n",
      "length of df_y: 14088, \n",
      "length of df_X: 14088\n",
      "train: 6902,\n",
      "valid: 2959,\n",
      "test: 4227\n",
      "offer type: informational \n",
      "length of df_y: 8080, \n",
      "length of df_X: 8080\n",
      "train: 3959,\n",
      "valid: 1697,\n",
      "test: 2424\n"
     ]
    }
   ],
   "source": [
    "offer_types = ['bogo','discount','informational']\n",
    "for offer_type in offer_types:\n",
    "    df = features[features[offer_type].isnull()==False].copy()\n",
    "    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    df = df[kept_features]\n",
    "\n",
    "    # we have to ensure that the colum 'bogo' has to be removed when processing the bogo offer trype. same procedure\n",
    "    # when processing the other offer types\n",
    "    remaining_offers = list(offer_types)\n",
    "    remaining_offers.remove(offer_type)\n",
    "    df = df.drop(['person','is_completed']+remaining_offers,axis=1)\n",
    "    if run_demographic_only:\n",
    "        demographic = ['age','income','F','M','member_since_month','bogo']\n",
    "        df = df[demographic].copy()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = pd.DataFrame(scaler.fit_transform(df))\n",
    "    df_y = scaled.iloc[:,-1:]\n",
    "    df_X = scaled.iloc[:,:-1]\n",
    "    print('offer type: {} \\nlength of df_y: {}, \\nlength of df_X: {}'.format(offer_type, len(df_y),len(df_X)))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "    print('train: {},\\nvalid: {},\\ntest: {}'.format(len(y_train),len(y_val),len(y_test)))\n",
    "    \n",
    "    # lets write the data to data directory\n",
    "    X_test.to_csv(os.path.join(data_dir, '{}_test.csv'.format(offer_type)), header=False, index=False)\n",
    "    y_test.to_csv(os.path.join(data_dir, '{}_y_test.csv'.format(offer_type)), header=False, index=False)\n",
    "    pd.concat([y_val, X_val], axis=1).to_csv(os.path.join(data_dir, '{}_validation.csv'.format(offer_type)), header=False, index=False)\n",
    "    pd.concat([y_train, X_train], axis=1).to_csv(os.path.join(data_dir, '{}_train.csv'.format(offer_type)), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets write the S3 locations into a dictionary of the form {offer:{test:...,train...,validation}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_validation.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_validation.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_train.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_test.csv\n",
      "s3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_validation.csv\n"
     ]
    }
   ],
   "source": [
    "prefix = 'capstone_starbucks_20201106'\n",
    "locations = {}\n",
    "for offer_type in offer_types:\n",
    "    usage_dict = {}\n",
    "    for usage in ['train','test','validation']:\n",
    "        location = session.upload_data(os.path.join(data_dir, '{}_{}.csv'.format(offer_type,usage)), key_prefix=prefix)\n",
    "        usage_dict[usage] = location\n",
    "        print(location)\n",
    "    locations[offer_type] = usage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bogo': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/bogo_validation.csv'},\n",
       " 'discount': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/discount_validation.csv'},\n",
       " 'informational': {'test': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_test.csv',\n",
       "  'train': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_train.csv',\n",
       "  'validation': 's3://sagemaker-us-east-2-330335126841/capstone_starbucks_20201106/informational_validation.csv'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train an xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above, we use this utility method to construct the image name for the training container.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "# Now that we know which container to use, we can construct the estimator object.\n",
    "xgb = sagemaker.estimator.Estimator(container, # The name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge', # The type of instance ot use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                                                        # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just train one model plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "connect the right input data to sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_type = 'bogo'\n",
    "train_location = locations[offer_type]['train']\n",
    "val_location = locations[offer_type]['validation']\n",
    "test_location = locations[offer_type]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-06 14:02:33 Starting - Starting the training job...\n",
      "2020-11-06 14:02:36 Starting - Launching requested ML instances......\n",
      "2020-11-06 14:03:40 Starting - Preparing the instances for training...\n",
      "2020-11-06 14:04:30 Downloading - Downloading input data...\n",
      "2020-11-06 14:04:46 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8469.97mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:08] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:05:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:05:08] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:05:08] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.467407#011validation-rmse:0.469731\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.445431#011validation-rmse:0.450377\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.430298#011validation-rmse:0.437217\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.419934#011validation-rmse:0.428734\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.412625#011validation-rmse:0.422641\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.407422#011validation-rmse:0.418249\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.403053#011validation-rmse:0.415496\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.400301#011validation-rmse:0.413159\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.398216#011validation-rmse:0.411852\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.396678#011validation-rmse:0.410958\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.39516#011validation-rmse:0.410636\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.394337#011validation-rmse:0.410398\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.393322#011validation-rmse:0.410127\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.392339#011validation-rmse:0.409808\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.391885#011validation-rmse:0.409834\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.39105#011validation-rmse:0.40968\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.390621#011validation-rmse:0.409684\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.389694#011validation-rmse:0.409607\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.389492#011validation-rmse:0.40972\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.388482#011validation-rmse:0.409889\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.388354#011validation-rmse:0.409819\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.387613#011validation-rmse:0.410005\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.387175#011validation-rmse:0.409996\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.386842#011validation-rmse:0.409922\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.386368#011validation-rmse:0.410266\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.386225#011validation-rmse:0.41032\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.385885#011validation-rmse:0.410388\u001b[0m\n",
      "\u001b[34m[14:05:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.385452#011validation-rmse:0.410511\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.389694#011validation-rmse:0.409607\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-06 14:05:20 Uploading - Uploading generated training model\n",
      "2020-11-06 14:05:20 Completed - Training job completed\n",
      "Training seconds: 50\n",
      "Billable seconds: 50\n"
     ]
    }
   ],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[32m2020-11-06T14:10:29.446:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:10:29 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 36\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:10:29 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:10:29:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_test(offer_type,usage):\n",
    "    return pd.read_csv(os.path.join(data_dir,'{}_y_{}.csv'.format(offer_type,usage)),header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-06-14-05-45-916/bogo_test.csv.out to data/bogo_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.read_csv(os.path.join(data_dir, 'bogo_test.csv.out'), header=None)\n",
    "y_test = get_y_test('bogo','test')\n",
    "print(confusion_matrix(y_test,y_pred.round()))\n",
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1346  693]\n",
      " [ 516 2461]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.66      0.69      2039\n",
      "         1.0       0.78      0.83      0.80      2977\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5016\n",
      "   macro avg       0.75      0.74      0.75      5016\n",
      "weighted avg       0.76      0.76      0.76      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred.round()))\n",
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train one model with all offer types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bogo': 'xgboost-2020-11-06-15-17-27-487',\n",
       " 'discount': 'xgboost-2020-11-06-15-26-25-194',\n",
       " 'informational': 'xgboost-2020-11-06-15-35-21-812'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-06 15:17:28 Starting - Starting the training job...\n",
      "2020-11-06 15:17:31 Starting - Launching requested ML instances......\n",
      "2020-11-06 15:18:53 Starting - Preparing the instances for training......\n",
      "2020-11-06 15:19:58 Downloading - Downloading input data\n",
      "2020-11-06 15:19:58 Training - Downloading the training image...\n",
      "2020-11-06 15:20:24 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:20:19:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:20:19:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8477.59mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:20:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:20:19] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:20:19] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:20:19:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:20:19] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:20:19] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 44 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.468993#011validation-rmse:0.47084\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 42 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.447923#011validation-rmse:0.451651\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 40 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.433752#011validation-rmse:0.438946\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 42 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.424152#011validation-rmse:0.430301\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 46 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.418136#011validation-rmse:0.425075\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 52 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.414312#011validation-rmse:0.421775\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 48 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.411509#011validation-rmse:0.419247\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 40 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.408891#011validation-rmse:0.416756\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 50 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.407203#011validation-rmse:0.414858\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.406344#011validation-rmse:0.413922\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 44 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.405677#011validation-rmse:0.413157\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.405078#011validation-rmse:0.412824\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.405059#011validation-rmse:0.412819\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.405047#011validation-rmse:0.41282\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.405044#011validation-rmse:0.41282\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.405046#011validation-rmse:0.41282\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.405039#011validation-rmse:0.412823\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.40504#011validation-rmse:0.412822\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.405039#011validation-rmse:0.412824\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 48 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.404208#011validation-rmse:0.412288\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.404207#011validation-rmse:0.412289\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.404207#011validation-rmse:0.412289\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.404206#011validation-rmse:0.41229\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.404204#011validation-rmse:0.412298\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.404204#011validation-rmse:0.412299\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.404204#011validation-rmse:0.412298\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.404205#011validation-rmse:0.412306\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 44 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.40354#011validation-rmse:0.412017\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.40354#011validation-rmse:0.412019\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.40354#011validation-rmse:0.412018\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.40354#011validation-rmse:0.41202\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.40354#011validation-rmse:0.412011\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.40354#011validation-rmse:0.412014\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.40354#011validation-rmse:0.412014\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.40354#011validation-rmse:0.412013\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.40354#011validation-rmse:0.412019\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.40354#011validation-rmse:0.41202\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.403541#011validation-rmse:0.412024\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.40354#011validation-rmse:0.412021\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.40354#011validation-rmse:0.412024\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.40354#011validation-rmse:0.412023\u001b[0m\n",
      "\u001b[34m[15:20:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.40354#011validation-rmse:0.412018\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.40354#011validation-rmse:0.412011\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-06 15:20:31 Completed - Training job completed\n",
      "Training seconds: 48\n",
      "Billable seconds: 48\n",
      "..............................\n",
      ".\u001b[32m2020-11-06T15:26:06.891:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:26:06 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:06:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:06:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:26:06 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:06:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:06:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:06:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:26:07:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:26:07:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-06-15-21-11-030/bogo_test.csv.out to data/bogo_test.csv.out\n",
      "2020-11-06 15:26:25 Starting - Starting the training job...\n",
      "2020-11-06 15:26:27 Starting - Launching requested ML instances......\n",
      "2020-11-06 15:27:31 Starting - Preparing the instances for training......\n",
      "2020-11-06 15:28:49 Downloading - Downloading input data...\n",
      "2020-11-06 15:29:23 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:29:24:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:29:24:INFO] File size need to be processed in the node: 1.31mb. Available memory size in the node: 8487.41mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:29:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:29:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:29:24] 6902x13 matrix with 89726 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:29:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:29:24] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:29:24] 2959x13 matrix with 38467 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 42 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.459935#011validation-rmse:0.461024\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 40 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.432729#011validation-rmse:0.434728\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.415176#011validation-rmse:0.417699\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 52 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.402914#011validation-rmse:0.405911\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 48 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.394702#011validation-rmse:0.398532\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 56 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.389641#011validation-rmse:0.393848\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 56 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.386085#011validation-rmse:0.390668\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.383613#011validation-rmse:0.388376\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 44 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.382214#011validation-rmse:0.387182\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.380949#011validation-rmse:0.386058\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 58 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.380271#011validation-rmse:0.385639\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.380055#011validation-rmse:0.385455\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.379929#011validation-rmse:0.385352\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 56 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.379519#011validation-rmse:0.385081\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.379464#011validation-rmse:0.385041\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.379433#011validation-rmse:0.38502\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.379394#011validation-rmse:0.384998\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.379377#011validation-rmse:0.384993\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.379371#011validation-rmse:0.384993\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 62 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.379372#011validation-rmse:0.384993\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.379371#011validation-rmse:0.384993\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.379367#011validation-rmse:0.384996\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.379367#011validation-rmse:0.384996\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.379367#011validation-rmse:0.384996\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.379366#011validation-rmse:0.385002\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 60 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.379366#011validation-rmse:0.385\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.379366#011validation-rmse:0.384998\u001b[0m\n",
      "\u001b[34m[15:29:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.379366#011validation-rmse:0.384997\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.379377#011validation-rmse:0.384993\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-06 15:29:36 Uploading - Uploading generated training model\n",
      "2020-11-06 15:29:36 Completed - Training job completed\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n",
      ".............................\u001b[32m2020-11-06T15:34:49.943:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:49:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:34:49 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:49:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:50:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:50:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:50:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:34:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:49:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:34:49 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:49:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:50:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:50:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:50:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:34:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-06-15-30-07-371/discount_test.csv.out to data/discount_test.csv.out\n",
      "2020-11-06 15:35:21 Starting - Starting the training job...\n",
      "2020-11-06 15:35:24 Starting - Launching requested ML instances......\n",
      "2020-11-06 15:36:29 Starting - Preparing the instances for training......\n",
      "2020-11-06 15:37:33 Downloading - Downloading input data...\n",
      "2020-11-06 15:38:21 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:38:21:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:38:21:INFO] File size need to be processed in the node: 0.76mb. Available memory size in the node: 8486.36mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:38:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:38:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:38:21] 3959x13 matrix with 51467 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:38:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[15:38:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[15:38:21] 1697x13 matrix with 22061 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 50 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.488838#011validation-rmse:0.490533\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.481857#011validation-rmse:0.484618\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 56 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.477328#011validation-rmse:0.48095\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.473231#011validation-rmse:0.4782\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 52 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.470946#011validation-rmse:0.476326\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 52 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.469836#011validation-rmse:0.475758\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 54 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.468474#011validation-rmse:0.474734\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 54 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.467713#011validation-rmse:0.474046\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 46 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.466494#011validation-rmse:0.473252\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.466415#011validation-rmse:0.473329\u001b[0m\n",
      "\u001b[34m[15:38:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.466396#011validation-rmse:0.473357\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.466358#011validation-rmse:0.47343\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 48 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.465853#011validation-rmse:0.472944\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.465859#011validation-rmse:0.472925\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 48 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.465097#011validation-rmse:0.47234\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.465103#011validation-rmse:0.47232\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.4651#011validation-rmse:0.47233\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.465094#011validation-rmse:0.472352\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.465085#011validation-rmse:0.472392\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.465079#011validation-rmse:0.472434\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.465077#011validation-rmse:0.472447\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.465075#011validation-rmse:0.472466\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.465079#011validation-rmse:0.472429\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.465072#011validation-rmse:0.47254\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.465072#011validation-rmse:0.472557\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 42 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.464153#011validation-rmse:0.472177\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 58 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.464153#011validation-rmse:0.472203\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.464154#011validation-rmse:0.472156\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.464154#011validation-rmse:0.472141\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.464154#011validation-rmse:0.472218\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.464154#011validation-rmse:0.472238\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.464154#011validation-rmse:0.472241\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 42 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.464157#011validation-rmse:0.472289\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.464153#011validation-rmse:0.472176\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.464153#011validation-rmse:0.472168\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.464153#011validation-rmse:0.472188\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.464153#011validation-rmse:0.472182\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.464155#011validation-rmse:0.472137\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.464156#011validation-rmse:0.472112\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.464155#011validation-rmse:0.472125\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.464154#011validation-rmse:0.472145\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.464156#011validation-rmse:0.472123\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.464158#011validation-rmse:0.472094\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 56 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.464154#011validation-rmse:0.472149\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 54 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.464153#011validation-rmse:0.472173\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.464154#011validation-rmse:0.472161\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.464155#011validation-rmse:0.472126\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.464157#011validation-rmse:0.472111\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.464155#011validation-rmse:0.472129\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.464155#011validation-rmse:0.472127\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 36 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:0.464154#011validation-rmse:0.472161\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 50 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:0.464153#011validation-rmse:0.472171\u001b[0m\n",
      "\u001b[34m[15:38:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 46 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:0.464156#011validation-rmse:0.472123\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.464158#011validation-rmse:0.472094\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-06 15:38:33 Uploading - Uploading generated training model\n",
      "2020-11-06 15:38:33 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n",
      ".................................\n",
      "\u001b[32m2020-11-06T15:44:23.346:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-06 15:44:23 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 15:44:23 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:15:44:23:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-2020-11-06-15-39-03-973/informational_test.csv.out to data/informational_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "for offer_type in offer_types:\n",
    "    train_location = locations[offer_type]['train']\n",
    "    val_location = locations[offer_type]['validation']\n",
    "    test_location = locations[offer_type]['test']\n",
    "    \n",
    "    s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "    s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "    xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})\n",
    "    xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "    trained_models[offer_type] = xgb_transformer.model_name\n",
    "    xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "    xgb_transformer.wait()\n",
    "    !aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bogo\n",
      "[[1331  708]\n",
      " [ 491 2486]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.65      0.69      2039\n",
      "         1.0       0.78      0.84      0.81      2977\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5016\n",
      "   macro avg       0.75      0.74      0.75      5016\n",
      "weighted avg       0.76      0.76      0.76      5016\n",
      "\n",
      "discount\n",
      "[[ 497  572]\n",
      " [ 343 2815]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.46      0.52      1069\n",
      "         1.0       0.83      0.89      0.86      3158\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      4227\n",
      "   macro avg       0.71      0.68      0.69      4227\n",
      "weighted avg       0.77      0.78      0.77      4227\n",
      "\n",
      "informational\n",
      "[[1309  187]\n",
      " [ 636  292]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.88      0.76      1496\n",
      "         1.0       0.61      0.31      0.42       928\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      2424\n",
      "   macro avg       0.64      0.59      0.59      2424\n",
      "weighted avg       0.65      0.66      0.63      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for offer_type in offer_types:\n",
    "    print(offer_type)\n",
    "    y_pred = pd.read_csv(os.path.join(data_dir, '{}_test.csv.out'.format(offer_type)), header=None)\n",
    "    y_test = get_y_test(offer_type,'test')\n",
    "    print(confusion_matrix(y_test,y_pred.round()))\n",
    "    print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model with hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'xgboost-201106-1413-015-b8fd35ee'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparameter_tuner.best_training_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u'xgboost-201106-1413-015-b8fd35ee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'xgboost-201106-1413-015-b8fd35ee'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_attached.base_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-06 14:31:34 Starting - Preparing the instances for training\n",
      "2020-11-06 14:31:34 Downloading - Downloading input data\n",
      "2020-11-06 14:31:34 Training - Training image download completed. Training in progress.\n",
      "2020-11-06 14:31:34 Uploading - Uploading generated training model\n",
      "2020-11-06 14:31:34 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:31:22:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:31:22:INFO] Setting up HPO optimized metric to be : rmse\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:31:22:INFO] File size need to be processed in the node: 1.5mb. Available memory size in the node: 8480.8mb\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:31:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:31:22] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:31:22] 8190x13 matrix with 106470 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:31:22:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:31:22] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:31:22] 3511x13 matrix with 45643 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.474964#011validation-rmse:0.476755\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.456647#011validation-rmse:0.459769\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.44267#011validation-rmse:0.446866\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 40 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.432549#011validation-rmse:0.437542\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.424635#011validation-rmse:0.430826\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.418571#011validation-rmse:0.425822\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.413181#011validation-rmse:0.421871\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.409909#011validation-rmse:0.419049\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 40 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.407269#011validation-rmse:0.416295\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 40 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.405746#011validation-rmse:0.415009\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.404216#011validation-rmse:0.41385\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 46 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.402987#011validation-rmse:0.41303\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.401882#011validation-rmse:0.411979\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.401116#011validation-rmse:0.41126\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.400142#011validation-rmse:0.410608\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 36 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.399249#011validation-rmse:0.410286\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.398606#011validation-rmse:0.409986\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 48 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.398275#011validation-rmse:0.409704\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 34 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.39813#011validation-rmse:0.409511\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 44 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.398091#011validation-rmse:0.409437\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 52 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.398092#011validation-rmse:0.409439\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 44 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.397898#011validation-rmse:0.409175\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.397384#011validation-rmse:0.408982\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 50 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.397202#011validation-rmse:0.408956\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 48 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.397201#011validation-rmse:0.408956\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.396734#011validation-rmse:0.408727\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.396454#011validation-rmse:0.408691\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 34 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.396349#011validation-rmse:0.408712\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 42 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.396231#011validation-rmse:0.408684\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 32 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.396078#011validation-rmse:0.408847\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 54 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.395927#011validation-rmse:0.408909\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.395919#011validation-rmse:0.408897\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 44 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.395805#011validation-rmse:0.408919\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 26 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.395603#011validation-rmse:0.408732\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 40 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.395606#011validation-rmse:0.408736\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.395605#011validation-rmse:0.408736\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 22 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.395461#011validation-rmse:0.408706\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 32 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.395258#011validation-rmse:0.408759\u001b[0m\n",
      "\u001b[34m[14:31:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 44 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.395255#011validation-rmse:0.408755\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.396231#011validation-rmse:0.408684\n",
      "\u001b[0m\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "xgb_attached = sagemaker.estimator.Estimator.attach(u'xgboost-201106-1413-015-b8fd35ee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'xgboost-201106-1413-015-b8fd35ee'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_transformer.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "\u001b[32m2020-11-06T14:50:55.380:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-11-06 14:50:55 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 37\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 38\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[35m[2020-11-06 14:50:55 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-11-06:14:50:55:INFO] Model loaded successfully for worker : 40\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#xgb_attached = sagemaker.estimator.Estimator.attach(xgb_hyperparameter_tuner.best_training_job())\n",
    "xgb_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-330335126841/xgboost-201106-1413-015-b8fd35ee-2020-11-06-14-46-30-851/bogo_test.csv.out to data/bogo_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1345  694]\n",
      " [ 492 2485]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.66      0.69      2039\n",
      "         1.0       0.78      0.83      0.81      2977\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5016\n",
      "   macro avg       0.76      0.75      0.75      5016\n",
      "weighted avg       0.76      0.76      0.76      5016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pd.read_csv(os.path.join(data_dir, 'bogo_test.csv.out'), header=None)\n",
    "y_test = get_y_test('bogo','test')\n",
    "print(confusion_matrix(y_test,y_pred.round()))\n",
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
